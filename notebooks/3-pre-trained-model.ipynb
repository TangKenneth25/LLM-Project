{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainDF = pd.read_csv('..//data//preprocessingTrainDF')\n",
    "testDF = pd.read_csv('..//data//preprocessingTestDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bowTokens to list\n",
    "def stringToList(dfCol):\n",
    "    return ast.literal_eval(dfCol)\n",
    "\n",
    "for df in [trainDF, testDF]:\n",
    "    df['bowTokens'] = df['bowTokens'].apply(stringToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanText</th>\n",
       "      <th>bowTokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film probably inspired godards masculin femini...</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleanText  \\\n",
       "0  rented curiousyellow video store controversy s...   \n",
       "1  curious yellow risible pretentious steaming pi...   \n",
       "2  avoid making type film future film interesting...   \n",
       "3  film probably inspired godards masculin femini...   \n",
       "4  oh brotherafter hearing ridiculous film umptee...   \n",
       "\n",
       "                                           bowTokens  label  \n",
       "0  [rented, curiousyellow, video, store, controve...      0  \n",
       "1  [curious, yellow, risible, pretentious, steami...      0  \n",
       "2  [avoid, making, type, film, future, film, inte...      0  \n",
       "3  [film, probably, inspired, godards, masculin, ...      0  \n",
       "4  [oh, brotherafter, hearing, ridiculous, film, ...      0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pretrained siebert/sentiment-roberta-large-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9988656044006348}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\", device=\"cuda\")\n",
    "print(sentiment_analysis(\"I love this!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis.tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncating strings to fit in model for max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def truncateJoinList(input_string):\n",
    "\n",
    "    # max words is not the model max length as the model does not tokenize by bow\n",
    "    # Limit to 200 words\n",
    "    maxWords = 200\n",
    "    if len(input_string) > maxWords:\n",
    "        truncated_words = input_string[:maxWords]\n",
    "        truncated_string = ' '.join(truncated_words)\n",
    "        return truncated_string\n",
    "    else:\n",
    "        return ' '.join(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the text columns\n",
    "for df in [trainDF, testDF]:\n",
    "    df['truncatedText'] = df['bowTokens'].apply(truncateJoinList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n",
      "457\n",
      "3258\n"
     ]
    }
   ],
   "source": [
    "# lengths \n",
    "print(len(trainDF['truncatedText'][17]))\n",
    "print(len(trainDF['bowTokens'][17]))\n",
    "print(len(trainDF['cleanText'][17]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predSentiment(df):\n",
    "    pred = []\n",
    "    for i in range(df.shape[0]):\n",
    "        pred.append(sentiment_analysis(df[i]))\n",
    "        print(i,end='\\r')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999\r"
     ]
    }
   ],
   "source": [
    "trainPred = predSentiment(trainDF['truncatedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999\r"
     ]
    }
   ],
   "source": [
    "testPred = predSentiment(testDF['truncatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting results in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def extractData(data):\n",
    "    labels = [item[0]['label'] for item in data]\n",
    "    scores = [item[0]['score'] for item in data]\n",
    "\n",
    "    return pd.DataFrame({'label': labels,'score': scores})\n",
    "\n",
    "trainPredDF = extractData(trainPred)\n",
    "testPredDF = extractData(testPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "# trainPredDF.to_csv('..//data//trainPred.csv', index=False)\n",
    "# testPredDF.to_csv('..//data//testPred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pretrained = testPredDF['label'].map({'NEGATIVE': 0, 'POSITIVE': 1}).values\n",
    "y_test = testDF['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     12500\n",
      "           1       0.93      0.88      0.90     12500\n",
      "\n",
      "    accuracy                           0.90     25000\n",
      "   macro avg       0.90      0.90      0.90     25000\n",
      "weighted avg       0.90      0.90      0.90     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The siebert sentiment -robertare pretrained model performed better, with average f1-score of 0.90 compared to the 0.87 from the logistic BoW model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
