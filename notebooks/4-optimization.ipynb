{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "import transformers, torch, accelerate, evaluate\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "ds = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging face access token has been copied to clipboard\n"
     ]
    }
   ],
   "source": [
    "# Copy access token to clipboard\n",
    "HFToken = os.getenv('HuggingFaceAccessToken')\n",
    "pd.DataFrame([HFToken]).to_clipboard(index=False,header=False)\n",
    "print('Hugging face access token has been copied to clipboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658be3132ab54dd680dda4f8753f375c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distilbert tokenizer and model\n",
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use the default preprocessor\n",
    "# important to ensure expected input to our model (i.e. same lemmatization modelling, stopwords, etc)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map function\n",
    "    # padding and truncation control for variable length sequences\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# apply to all datasets with .map(). Built in function of the HF datasets class\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred # raw outputs, actual labels\n",
    "    predictions = np.argmax(logits, axis=-1) #prediction is the highest output probability\n",
    "    return metric.compute(predictions=predictions, references=labels) # accuracy computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tokenized_datasets['train']\n",
    "eval_ds = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8340499a8c4e689fb68d5d255bf0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2901, 'grad_norm': 15.448760986328125, 'learning_rate': 1.3602047344849649e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2386, 'grad_norm': 8.095005989074707, 'learning_rate': 7.204094689699297e-06, 'epoch': 0.64}\n",
      "{'loss': 0.2109, 'grad_norm': 11.429597854614258, 'learning_rate': 8.061420345489445e-07, 'epoch': 0.96}\n",
      "{'train_runtime': 1145.7401, 'train_samples_per_second': 21.82, 'train_steps_per_second': 1.364, 'train_loss': 0.24505678629615868, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.24505678629615868, metrics={'train_runtime': 1145.7401, 'train_samples_per_second': 21.82, 'train_steps_per_second': 1.364, 'total_flos': 3311684966400000.0, 'train_loss': 0.24505678629615868, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='..//models//fineTunedModel',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ef9704313948ba8ca5e23c169c34a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19233736395835876,\n",
       " 'eval_f1': 0.9285971727203556,\n",
       " 'eval_runtime': 401.6952,\n",
       " 'eval_samples_per_second': 62.236,\n",
       " 'eval_steps_per_second': 3.891,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('..//models//fineTunedModel\\\\tokenizer_config.json',\n",
       " '..//models//fineTunedModel\\\\special_tokens_map.json',\n",
       " '..//models//fineTunedModel\\\\vocab.txt',\n",
       " '..//models//fineTunedModel\\\\added_tokens.json',\n",
       " '..//models//fineTunedModel\\\\tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model('..//models//fineTunedModel')\n",
    "tokenizer.save_pretrained('..//models//fineTunedModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizating Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a sample of 2500 entries (1250 positive and 1250 negative) to test hyperparameters. This allows for quicker experimentation and training within a reasonable timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeReviewsTrain = tokenized_datasets['train'].filter(lambda example: example['label'] == 0)\n",
    "positiveReviewsTrain = tokenized_datasets['train'].filter(lambda example: example['label'] == 1)\n",
    "\n",
    "negativeReviewsTest = tokenized_datasets['test'].filter(lambda example: example['label'] == 0)\n",
    "positiveReviewsTest = tokenized_datasets['test'].filter(lambda example: example['label'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = concatenate_datasets([\n",
    "        negativeReviewsTrain.shuffle(seed=42).select(range(1250)), \n",
    "        positiveReviewsTrain.shuffle(seed=42).select(range(1250))]).shuffle(seed=42)\n",
    "\n",
    "eval_ds = concatenate_datasets([\n",
    "        negativeReviewsTest.shuffle(seed=42).select(range(1250)), \n",
    "        positiveReviewsTest.shuffle(seed=42).select(range(1250))]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running and tuning training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"imdbSentimentAnalysis\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   learning_rate=1e-3,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=1,\n",
    "   weight_decay=0.01,\n",
    "   warmup_steps=250,\n",
    "   output_dir=repo_name,\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e84d6a95d44243be0444475c860c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.18454618752002716,\n",
       " 'eval_model_preparation_time': 0.002,\n",
       " 'eval_f1': 0.9326961369972122,\n",
       " 'eval_runtime': 34.715,\n",
       " 'eval_samples_per_second': 72.015,\n",
       " 'eval_steps_per_second': 4.523}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"imdbSentimentAnalysis\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   learning_rate=2e-5, # Tried 1e-5, 3e-5, 5e-5\n",
    "   per_device_train_batch_size=16, \n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=1, # Tried 2, 3\n",
    "   weight_decay=0.01, # Tried 0.1, 0.005, 0.001\n",
    "   warmup_steps=300, # Tried 250, 300, 350\n",
    "   output_dir=repo_name,\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running full model again with adjusted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tokenized_datasets['train']\n",
    "eval_ds = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"imdbSentimentAnalysis\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   learning_rate=1e-4,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=1,\n",
    "   weight_decay=0.01,\n",
    "   warmup_steps=2000,\n",
    "   output_dir=repo_name,\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ffe007d67544b897fd4c3e6860f538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19233736395835876,\n",
       " 'eval_model_preparation_time': 0.002,\n",
       " 'eval_f1': 0.9285971727203556,\n",
       " 'eval_runtime': 359.7792,\n",
       " 'eval_samples_per_second': 69.487,\n",
       " 'eval_steps_per_second': 4.344}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very little improvement with the additional training arguments and adjustment to thel earning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('..//models//fineTunedModelOptimized\\\\tokenizer_config.json',\n",
       " '..//models//fineTunedModelOptimized\\\\special_tokens_map.json',\n",
       " '..//models//fineTunedModelOptimized\\\\vocab.txt',\n",
       " '..//models//fineTunedModelOptimized\\\\added_tokens.json',\n",
       " '..//models//fineTunedModelOptimized\\\\tokenizer.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model('..//models//fineTunedModelOptimized')\n",
    "tokenizer.save_pretrained('..//models//fineTunedModelOptimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61721460e18c432788e938553c1d0615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 17 LFS files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa857d45d60c41bdbe58a420202dd018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609361.DESKTOP-IJEVO1K.17432.6:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff2a04e9ac3436dbb21d779ed85c615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609007.DESKTOP-IJEVO1K.17432.3:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7071645b90b4c2b971a2fe2c83317e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609147.DESKTOP-IJEVO1K.17432.4:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13c909aa6914e15adf697c0dd135e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609255.DESKTOP-IJEVO1K.17432.5:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34da1083b8384d4698ab89d671df63a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6a943af5684d85954cd926f6a55f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609409.DESKTOP-IJEVO1K.17432.7:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534037e7df4b47f5874d1e3a5df941a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609469.DESKTOP-IJEVO1K.17432.8:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f86c71d4c0f46ca8c70618579f3d9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609525.DESKTOP-IJEVO1K.17432.9:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b03638896c433a90834fb56c0eb128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609615.DESKTOP-IJEVO1K.17432.10:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be351dc9bcf146c38794c3d44aca18c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609660.DESKTOP-IJEVO1K.17432.11:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be98328f06604e8f85655ccb2ba5ac93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609779.DESKTOP-IJEVO1K.17432.12:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1458b9a1c7d4a5e990eeb62bb32577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609922.DESKTOP-IJEVO1K.17432.14:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7abff54cc7f453fb5302515d23ee776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725609821.DESKTOP-IJEVO1K.17432.13:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b936437e10433785eb006178b67dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725610214.DESKTOP-IJEVO1K.17432.15:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7436fadcfc45838507e334f369e1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725610281.DESKTOP-IJEVO1K.17432.16:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8056d03069844a43866f5bdb86c69e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725610789.DESKTOP-IJEVO1K.17432.17:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6edad6fd6d04f748efeb573b0c8bd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ktang5/imdbSentimentAnalysis/commit/e3a7ad26e6012b02a45e631029795a25eb26246a', commit_message='End of training', commit_description='', oid='e3a7ad26e6012b02a45e631029795a25eb26246a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Model on HuggingFace hub using pipeline module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9833689332008362},\n",
       " {'label': 'LABEL_0', 'score': 0.9626513123512268}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on new text with uploaded model on huggingface\n",
    "from transformers import pipeline\n",
    "\n",
    "data = [\"This movie is good\", \"This is not good, very bad\"] \n",
    "my_model = pipeline(model=\"ktang5/imdbSentimentAnalysis\")\n",
    "my_model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lighthouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
